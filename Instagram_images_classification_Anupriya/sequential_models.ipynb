{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCCjUPYXId2g"
      },
      "source": [
        "### Pre-requisite - Download Datasets\n",
        "Run all the cells below after downloading the required kaggle.json file (follow [these steps](https://www.kaggle.com/discussions/general/156610))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnRTm1as5bAv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEPBdBI35gpF"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TukCYQd75ygu"
      },
      "outputs": [],
      "source": [
        "!ls -lha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIX8VjjI50IO"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWJYqxgs52O5"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e50YZGKS54yB"
      },
      "outputs": [],
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzWtOaF6561h"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv6iw7z558VX"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d anupriyakkumari/instagram-5-classes-dataset-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tddLrD895_PB"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d anupriyakkumari/instagram-5-classes-dataset-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQAYhvU45_qg"
      },
      "outputs": [],
      "source": [
        "!unzip instagram-5-classes-dataset-1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMu7FWbJ6BoS"
      },
      "outputs": [],
      "source": [
        "!unzip instagram-5-classes-dataset-2.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS96Kk9MOpO8"
      },
      "source": [
        "### Note - rename the folders for consistency.\n",
        "We renamed them to - Instagram_Dataset_1 and Instagram_Dataset_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y35dboo_-Fas"
      },
      "source": [
        "#4.1 (Sequential Models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6fR3xz_XOB"
      },
      "source": [
        "### 4.1.1 Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4P8gCy5_cW5"
      },
      "source": [
        "In this approach, we will again first import required libraries, then upload our dataset in a similar way as above but this time we have a single folder containing subfolders of the 5 classes and another folder for testing on unseen data also containing subfolders of 5 classes.\n",
        "Run each cell one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUOiQbFM9Kqg"
      },
      "outputs": [],
      "source": [
        "#loading essential libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znXWuxgw-Wq8"
      },
      "source": [
        "Here we load the dataset and again set the paramters as per requirement. We are splitting the training dataset into train and validation, with validation containing 10% of the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeZmkkXYDZPm"
      },
      "outputs": [],
      "source": [
        "#setting important parameters and loading the three required datasets\n",
        "batch_size = 64\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "data_dir= \"/content/Instagram_Dataset_1/classes\"\n",
        "#using bigger dataset for now\n",
        "data_dir_new=\"/content/Instagram_Dataset_2/classes\"\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir_new,\n",
        "  validation_split=0.1,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir_new,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4-ymBp_HuLJ"
      },
      "outputs": [],
      "source": [
        "#creating test_ds and loading images\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "test_dir= \"/content/Instagram_Dataset_2/test\"\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KOzBlry-ojY"
      },
      "source": [
        "Printing the dimension of the object generated by tf.keras.utils.image_dataset_from_directory function which is a tf.data.dataset object - float32 tensor and int32 tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQB8YQn71kv-"
      },
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3ptzCFSEo7d"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sPoyXNhfjbS"
      },
      "source": [
        "Plotting 9 images from batch specified in .take() - random each time because of seed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ctfcetgESuc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGJiBjy-ajJc"
      },
      "outputs": [],
      "source": [
        "#autotuning data and applying prefetch\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScYh29pfaxDS"
      },
      "outputs": [],
      "source": [
        "# creating data augmentation layer\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.1),\n",
        "  tf.keras.layers.RandomContrast(factor=0.3),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhdwCKBXa2sy"
      },
      "outputs": [],
      "source": [
        "# plotting one augmented image\n",
        "for image, _ in train_ds.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = image[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "    plt.imshow(augmented_image[0] / 255)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNn5PXYFYLFW"
      },
      "outputs": [],
      "source": [
        "# creating normalisation layer to rescale image\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtJQNsaeqUVm"
      },
      "outputs": [],
      "source": [
        "#initial sequential network built\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "model41 = tf.keras.Sequential([\n",
        "  normalization_layer,\n",
        "  data_augmentation,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU7ez5L1Wut4"
      },
      "outputs": [],
      "source": [
        "# compiling sequential model\n",
        "model41.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8N2_5PNGdog"
      },
      "outputs": [],
      "source": [
        "#finding the right value of epochs is tough as we might risk overfitting the model i.e., when accuracy > val_accuracy\n",
        "model41.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd0VjSCR_Pct"
      },
      "source": [
        "### 4.1.2 Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccrq7WIrrLbu"
      },
      "outputs": [],
      "source": [
        "#saving model so that we don't have to do the above steps again\n",
        "model41.save('/content/gdrive/MyDrive/Image_Classification/model_seq_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no9oMYDe7QP-"
      },
      "source": [
        "### 4.1.3 Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKXgzo8qKTki"
      },
      "outputs": [],
      "source": [
        "# evaluating on test_ds and val_ds and train_ds also\n",
        "test_loss1, test_acc1 = model41.evaluate(test_ds)\n",
        "val_loss1, val_acc1=model41.evaluate(val_ds)\n",
        "train_loss1,train_acc1=model41.evaluate(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhyNX98zKXo-"
      },
      "outputs": [],
      "source": [
        "print('Test loss :', test_loss1, 'Test accuracy:', test_acc1)\n",
        "print('Val loss :', val_loss1, 'Val accuracy:', val_acc1)\n",
        "print('Train loss :', train_loss1, 'Train accuracy:', train_acc1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F-dntdVFxXE"
      },
      "source": [
        "#4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKqe3U20_mUc"
      },
      "source": [
        "### 4.2.1 Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K15fhQJIGQfY"
      },
      "outputs": [],
      "source": [
        "#second sequential model\n",
        "#accuracy stuck after a certain point (haven't checked why yet)\n",
        "model42 = tf.keras.Sequential([\n",
        "    normalization_layer,\n",
        "  data_augmentation,\n",
        "tf.keras.layers.Conv2D(16,(3,3),activation = tf.nn.relu,input_shape=(180,180, 3)),\n",
        "tf.keras.layers.MaxPooling2D(2,2),\n",
        "tf.keras.layers.Conv2D(32,(3,3),activation = tf.nn.relu),\n",
        "tf.keras.layers.MaxPooling2D(2,2),\n",
        "tf.keras.layers.Conv2D(64,(3,3),activation = tf.nn.relu),\n",
        "tf.keras.layers.MaxPooling2D(2,2),\n",
        "tf.keras.layers.Conv2D(128,(3,3),activation = tf.nn.relu),\n",
        "tf.keras.layers.MaxPooling2D(2,2),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dropout(0.5),\n",
        "tf.keras.layers.Dense(512,kernel_regularizer = tf.keras.regularizers.l2(0.001), activation = tf.nn.relu),\n",
        "tf.keras.layers.Dense(5,activation = tf.nn.relu)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFYBHC2rDIcs"
      },
      "outputs": [],
      "source": [
        "model42.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OcjTcDpDLyu"
      },
      "outputs": [],
      "source": [
        "#finding the right value of epochs is tough, we run epochs until accuracy> val_accuracy then we stop\n",
        "model42.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dqcfdC_ugY"
      },
      "source": [
        "### 4.2.2 Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQTLI8VDRtZ"
      },
      "outputs": [],
      "source": [
        "model42.save('/content/gdrive/MyDrive/Image_Classification/model_seq_2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ctGwHEdAWQh"
      },
      "source": [
        "### 4.2.3 Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwAWm5zEDbh4"
      },
      "outputs": [],
      "source": [
        "test_loss2, test_acc2 = model42.evaluate(test_ds)\n",
        "val_loss2, val_acc2=model42.evaluate(val_ds)\n",
        "train_loss2,train_acc2=model42.evaluate(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-eW_tXSDny8"
      },
      "outputs": [],
      "source": [
        "print('Test loss :', test_loss2, 'Test accuracy:', test_acc2)\n",
        "print('Test loss :', val_loss2, 'Test accuracy:', val_acc2)\n",
        "print('Test loss :', train_loss2, 'Test accuracy:', train_acc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyJigz_0jWxt"
      },
      "source": [
        "#4.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eESIS20_44q"
      },
      "source": [
        "### 4.3.1 Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmLiKFNZQtyf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalization_layer)\n",
        "model.add(data_augmentation)\n",
        "#### Input Layer ####\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n",
        "                 activation='relu', input_shape=(128, 128, 3)))\n",
        "\n",
        "#### Convolutional Layers ####\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))  # Pooling\n",
        "model.add(Dropout(0.2)) # Dropout\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (5,5), activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#### Fully-Connected Layer ####\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.build((None,180,180,3))\n",
        "model.summary() # a handy way to inspect the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBm3uq3O2YqA"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXySH7dhRJbD"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "steps_per_epoch = 82\n",
        "val_steps = 10\n",
        "\n",
        "n_epochs = 5\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Saves Keras model after each epoch\n",
        "checkpointer = ModelCheckpoint(filepath='img_model.weights.best.hdf5',\n",
        "                               verbose=1,\n",
        "                               save_best_only=True)\n",
        "\n",
        "# Early stopping to prevent overtraining and to ensure decreasing validation loss\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')\n",
        "\n",
        "# tensorboard_callback = TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "# Actual fitting of the model\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=n_epochs,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=val_ds,\n",
        "                    validation_steps=val_steps,\n",
        "                    callbacks=[early_stop, checkpointer, PlotLossesKeras()],\n",
        "                    verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMBn9yuaACrz"
      },
      "source": [
        "### 4.3.2 Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DbI17mZR82p"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/gdrive/MyDrive/Image_Classification/model_seq_3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUIMyW1CA6xi"
      },
      "source": [
        "### 4.3.3 Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXmjDCudSVqt"
      },
      "outputs": [],
      "source": [
        "#third model\n",
        "model.load_weights(\"/content/gdrive/MyDrive/Image_Classification/model_seq_3.h5\")\n",
        "\n",
        "predicted_classes = model.predict_classes(test_ds)\n",
        "\n",
        "class_indices = train_ds.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "true_classes = test_ds.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfKMt-5vSmG3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def display_results(y_true, y_preds, class_labels):\n",
        "\n",
        "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n",
        "                          columns=class_labels).T\n",
        "\n",
        "    results.rename(columns={0: 'Precision', 1: 'Recall',\n",
        "                            2: 'F-Score', 3: 'Support'}, inplace=True)\n",
        "\n",
        "    results.sort_values(by='F-Score', ascending=False, inplace=True)\n",
        "    global_acc = accuracy_score(y_true, y_preds)\n",
        "\n",
        "    print(\"Overall Categorical Accuracy: {:.2f}%\".format(global_acc*100))\n",
        "    return results\n",
        "\n",
        "def plot_predictions(y_true, y_preds, test_generator, class_indices):\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):\n",
        "        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n",
        "        ax.imshow(np.squeeze(test_generator[idx]))\n",
        "        pred_idx = y_preds[idx]\n",
        "        true_idx = y_true[idx]\n",
        "\n",
        "        plt.tight_layout()\n",
        "        ax.set_title(\"{}\\n({})\".format(class_indices[pred_idx], class_indices[true_idx]),\n",
        "                     color=(\"green\" if pred_idx == true_idx else \"red\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bAFDYKd53zC"
      },
      "outputs": [],
      "source": [
        "model.load_weights('img_model.weights.best.hdf5')\n",
        "\n",
        "predicted_classes = model.predict_classes(testgen)\n",
        "\n",
        "class_indices = traingen.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "true_classes = testgen.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0BWgFUL5oxa"
      },
      "outputs": [],
      "source": [
        "plot_predictions(true_classes, predicted_classes, testgen, class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RstCHW5b5hlF"
      },
      "outputs": [],
      "source": [
        "display_results(true_classes, predicted_classes, class_indices.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOos4Qg-7Y3d"
      },
      "source": [
        "Plotting images and labels for unseen data on any model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2NjP77Ap1IQ"
      },
      "outputs": [],
      "source": [
        "# using the first model to display images on unseen data with predicted labels - very inaccuarate, as expected.\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = load_model('/content/gdrive/MyDrive/Image_Classification/model_seq_1.h5')\n",
        "\n",
        "# Set the path to the folder containing the images\n",
        "folder_path = '/content/Instagram_Dataset_2/unseen'\n",
        "\n",
        "# Loop through the images in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "\n",
        "    # Load the image\n",
        "    img = image.load_img(os.path.join(folder_path, filename), target_size=(180, 180))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Reshape the array to match the input shape of the VGG16 model\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Preprocess the input image (normalize pixel values to be between -1 and 1)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Make a prediction on the image\n",
        "    preds = model.predict(img_array)\n",
        "    print(preds)\n",
        "\n",
        "    # Decode the prediction into a human-readable label\n",
        "    label = int(preds.argmax(axis=-1))\n",
        "    label_name={0:'beauty',1:'food',2:'memes',3:'pets',4:'travel'}\n",
        "    #label_name={0:'animals',1:'beauty',2:'food',3:'memes',4:'travel'}\n",
        "\n",
        "\n",
        "    # Display the image with predicted label\n",
        "    plt.imshow(img)\n",
        "    plt.title(label_name[label])\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiozVWij2BMg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}